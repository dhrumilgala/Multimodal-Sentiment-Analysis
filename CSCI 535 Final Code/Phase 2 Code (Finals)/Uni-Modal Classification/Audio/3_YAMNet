{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"JEpZ2ISx5Ser"},"outputs":[],"source":["import os\n","import numpy as np\n","import soundfile as sf\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","import librosa\n","import pandas as pd\n","import json\n","from sklearn.model_selection import train_test_split\n","\n","# Define the sampling rate.\n","SR = 16000\n","\n","# Load the YAMNet model.\n","YAMNET_MODEL = hub.load('https://tfhub.dev/google/yamnet/1')\n","\n","def extract_yamnet_features(audio_file_path,emotion_label):\n","    # extract YAMNet features\n","    y, sr = librosa.load(audio_file_path, sr=16000)\n","    if len(y) < 16000:\n","        return None, None, None # return None if audio is less than 1 second long\n","    y = y[:16000]\n","    feature_vectors = YAMNET_MODEL(y)\n","\n","    # Stack the feature vectors into a single numpy array.\n","    feature_vectors = np.array(feature_vectors)\n","    feature_vectors = feature_vectors.flatten()  # combine the feature vectors into a single vector\n","    feature_vectors = feature_vectors.tolist()   # convert the numpy array to a list\n","\n","    return feature_vectors, emotion_label\n","\n","\n","# Load the metadata\n","metadata_path = '/content/drive/MyDrive/535/IEMOCAP_full_release/meta_data/meta_data.json'\n","with open(metadata_path, 'r') as f:\n","    metadata = json.load(f)\n","\n","# Extract the YAMNet features for all audio files in the directory.\n","audio_dir = '/content/drive/MyDrive/535/IEMOCAP_full_release/'\n","\n","features = []\n","labels = []\n","counter = 0\n","for item in metadata['meta_data']:\n","    counter+=1\n","    print(counter)\n","    # Load the audio file and extract the relevant segment\n","    audio_file_path = os.path.join(audio_dir, item['path'])\n","    emotion_label = item['label']\n","\n","    feature_vector, label = extract_yamnet_features(audio_file_path, emotion_label)\n","    if feature_vector is not None:\n","        features.append(feature_vector)\n","        if label:\n","          labels.append(metadata['labels'][emotion_label])\n","        else:\n","          labels.append(metadata['labels']['nue'])\n","\n","# Stack the feature vectors into a single numpy array.\n","features = np.array(features)\n"]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","from sklearn.metrics import classification_report\n","\n","combined_features = []\n","for i in range(features_df.shape[0]):\n","    feature_vector = []\n","    for j in range(features_df.shape[1]):\n","        feature = features_df.iloc[i, j]\n","    if isinstance(feature, float):\n","        feature_vector.append([feature])\n","    else:\n","        feature_vector.extend(feature)\n","    combined_features.append(feature_vector)"],"metadata":{"id":"UCLHeEbX5e91"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","# Extracted feature vectors are stacked into a single numpy array called `features`.\n","\n","features_df = pd.DataFrame(combined_features)\n","labels_df = pd.DataFrame(labels, columns=['label'])\n","\n","print(features_df)\n","print(labels_df)\n","# Concatenate the features, labels, and file names along the columns.\n","all_data_df = pd.concat([labels_df, features_df ], axis=1)\n","\n","# Save the features as a CSV file.\n","all_data_df.to_csv('/content/drive/MyDrive/535/YAMnet/features.csv', index=False)"],"metadata":{"id":"JWWbPmGa5tHa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert the list of lists into a NumPy array.\n","combined_features = np.array(combined_features)\n","\n","# Split the data into training and testing sets.\n","X_train, X_test, y_train, y_test = train_test_split(combined_features, labels_df, test_size=0.2, random_state=42)\n","\n","# Convert the list of arrays into a 2D NumPy array.\n","X_train_2d = np.vstack(X_train)\n","# Reshape the 2D array to have the same number of samples as y_train\n","X_train_2d = X_train_2d.reshape(len(X_train), -1)\n","\n","# Train a SVM classifier.\n","svm = SVC(kernel='linear')\n","svm.fit(X_train_2d, y_train)\n","\n","# Convert the list of arrays into a 2D NumPy array for the test set.\n","X_test_2d = np.vstack(X_test)\n","# Reshape the 2D array to have the same number of samples as y_test\n","X_test_2d = X_test_2d.reshape(len(X_test), -1)\n","\n","# Test the SVM classifier.\n","y_pred = svm.predict(X_test_2d)\n","\n","# Print the classification report.\n","print(classification_report(y_test, y_pred, zero_division=1))\n","\n"],"metadata":{"id":"v4b8Olsi526J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681956040367,"user_tz":420,"elapsed":206,"user":{"displayName":"Shrutika Singh","userId":"15254678382012429631"}},"outputId":"be03ed13-3088-4c29-eef7-dfb3e526e92a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\t        precision \t recall \tf1-score \tsupport\n","\t    0 \t     0.75\t   0.90 \t    0.82 \t     20\n","\t    1 \t     0.80\t   0.70 \t    0.75 \t     23\n","\t    2 \t     0.50\t   0.45 \t    0.48 \t     11\n","\t    3 \t     0.63\t   0.67 \t    0.64 \t     18\n","     accuracy  \t         \t       \t    \t    0.72\t     54\n","    macro avg \t     0.68\t   0.68 \t    0.68 \t     34\n"," weighted avg \t     0.72\t   0.72 \t    0.72 \t     45\n"]}]}]}