{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Explain where we got the text and audio features from the files\n"," "],"metadata":{"id":"fVEznsbwMO7Y"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"CIXndL8nBNql"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import pickle\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Dense, Dropout, Embedding, GRU, Bidirectional, concatenate, Input\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score\n","\n","# load the feature files\n","audio_features = pd.read_csv('audio_features.csv')\n","text_features = pd.read_csv('text_features.csv')\n","\n","# combine the features and labels\n","combined_features = pd.concat([audio_features, text_features], axis=1)\n","\n","# drop the duplicate labels column\n","combined_features = combined_features.loc[:,~combined_features.columns.duplicated()]\n","\n","# split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(combined_features.drop('label', axis=1), \n","                                                    combined_features['label'], test_size=0.2, random_state=42)\n"]},{"cell_type":"markdown","source":["GRU"],"metadata":{"id":"VOTAudQsC6AC"}},{"cell_type":"code","source":["# Tokenize the text data\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(X_train['transcription'])\n","vocab_size = len(tokenizer.word_index) + 1\n","\n","# Convert text data to sequences\n","maxlen = 200\n","x_train_text_seq = tokenizer.texts_to_sequences(X_train['transcription'])\n","x_train_text_seq = pad_sequences(x_train_text_seq, padding='post', maxlen=maxlen)\n","x_test_text_seq = tokenizer.texts_to_sequences(X_test['transcription'])\n","x_test_text_seq = pad_sequences(x_test_text_seq, padding='post', maxlen=maxlen)\n","\n","# Define the audio model architecture\n","audio_model = Sequential()\n","audio_model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]-1))\n","audio_model.add(Dense(32, activation='relu'))\n","audio_model.add(Dense(6, activation='softmax'))\n","\n","# Compile the audio model\n","audio_model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])\n","\n","# Train the audio model\n","audio_model.fit(X_train.drop('transcription', axis=1), tf.keras.utils.to_categorical(y_train, num_classes=6),\n","                epochs=25, batch_size=8, validation_data=(X_test.drop('transcription', axis=1), tf.keras.utils.to_categorical(y_test, num_classes=6)))\n","\n","# Define the text model architecture\n","text_input = Input(shape=(maxlen,))\n","embedding_layer = Embedding(vocab_size, 100, input_length=maxlen)(text_input)\n","text_gru_1 = Bidirectional(GRU(64, return_sequences=True))(embedding_layer)\n","text_drop_1 = Dropout(0.5)(text_gru_1)\n","text_gru_2 = Bidirectional(GRU(32))(text_drop_1)\n","text_drop_2 = Dropout(0.5)(text_gru_2)\n","text_dense = Dense(64, activation='relu')(text_drop_2)\n","text_output = Dense(6, activation='softmax')(text_dense)\n","text_model = Model(inputs=text_input, outputs=text_output)\n","\n","# Compile the text model\n","text_model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])\n","\n","# Train the text model\n","text_model.fit(x_train_text_seq, tf.keras.utils.to_categorical(y_train, num_classes=6),\n","               epochs=25, batch_size=8\n","\n","# Train the model\n","history = model.fit(x_train_text_seq, tf.keras.utils.to_categorical(y_train, num_classes=6),\n","                    epochs=25, batch_size=8, validation_data=(x_test_text_seq, tf.keras.utils.to_categorical(y_test, num_classes=6)))\n","\n","# Compile the audio model\n","audio_model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])\n","\n","# Train the audio model\n","audio_model.fit(X_train.drop('transcription', axis=1), tf.keras.utils.to_categorical(y_train, num_classes=6),\n","                epochs=25, batch_size=8, validation_data=(X_test.drop('transcription', axis=1), tf.keras.utils.to_categorical(y_test, num_classes=6)))\n","\n","# Evaluate the model performance\n","_, train_acc = model.evaluate(x_train_text_seq, tf.keras.utils.to_categorical(y_train, num_classes=6), verbose=0)\n","_, test_acc = model.evaluate(x_test_text_seq, tf.keras.utils.to_categorical(y_test, num_classes=6), verbose=0)\n","print('Train Accuracy: %.3f, Test Accuracy: %.3f' % (train_acc, test_acc))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rg5-Q5RQG1ui","executionInfo":{"status":"ok","timestamp":1681868258411,"user_tz":420,"elapsed":206,"user":{"displayName":"Shrutika Singh","userId":"15254678382012429631"}},"outputId":"1ee93c9d-288d-4a40-904f-a1c9e16f15dd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/25\n","573/573 [==============================] - 153s 256ms/step - loss: 1.7335 - accuracy: 0.2837 - val_loss: 1.6801 - val_accuracy: 0.2949\n","Epoch 2/25\n","573/573 [==============================] - 136s 238ms/step - loss: 1.5247 - accuracy: 0.3884 - val_loss: 1.3838 - val_accuracy: 0.4599\n","Epoch 3/25\n","573/573 [==============================] - 137s 239ms/step - loss: 1.3378 - accuracy: 0.4615 - val_loss: 1.2652 - val_accuracy: 0.4956\n","Epoch 4/25\n","573/573 [==============================] - 136s 237ms/step - loss: 1.2092 - accuracy: 0.5093 - val_loss: 1.1817 - val_accuracy: 0.5113\n","Epoch 5/25\n","573/573 [==============================] - 133s 233ms/step - loss: 1.1323 - accuracy: 0.5350 - val_loss: 1.1538 - val_accuracy: 0.5253\n","Epoch 6/25\n","573/573 [==============================] - 133s 232ms/step - loss: 1.0744 - accuracy: 0.5586 - val_loss: 1.1477 - val_accuracy: 0.5384\n","Epoch 7/25\n","573/573 [==============================] - 133s 232ms/step - loss: 1.0299 - accuracy: 0.5719 - val_loss: 1.1089 - val_accuracy: 0.5401\n","Epoch 8/25\n","573/573 [==============================] - 141s 246ms/step - loss: 0.9992 - accuracy: 0.5898 - val_loss: 1.0953 - val_accuracy: 0.5541\n","Epoch 9/25\n","573/573 [==============================] - 136s 237ms/step - loss: 0.9637 - accuracy: 0.6090 - val_loss: 1.0920 - val_accuracy: 0.5637\n","Epoch 10/25\n","573/573 [==============================] - 138s 240ms/step - loss: 0.9271 - accuracy: 0.6190 - val_loss: 1.0927 - val_accuracy: 0.5759\n","Epoch 11/25\n","573/573 [==============================] - 142s 248ms/step - loss: 0.8857 - accuracy: 0.6374 - val_loss: 1.0873 - val_accuracy: 0.5707\n","Epoch 12/25\n","573/573 [==============================] - 132s 231ms/step - loss: 0.8576 - accuracy: 0.6502 - val_loss: 1.0996 - val_accuracy: 0.5733\n","Epoch 13/25\n","573/573 [==============================] - 141s 246ms/step - loss: 0.8389 - accuracy: 0.6550 - val_loss: 1.1211 - val_accuracy: 0.5716\n","Epoch 14/25\n","573/573 [==============================] - 134s 234ms/step - loss: 0.8184 - accuracy: 0.6688 - val_loss: 1.1218 - val_accuracy: 0.5750\n","Epoch 15/25\n","573/573 [==============================] - 133s 232ms/step - loss: 0.7952 - accuracy: 0.6727 - val_loss: 1.1415 - val_accuracy: 0.5707\n","Epoch 16/25\n","573/573 [==============================] - 135s 235ms/step - loss: 0.7688 - accuracy: 0.6937 - val_loss: 1.1430 - val_accuracy: 0.5846\n","Epoch 17/25\n","573/573 [==============================] - 132s 231ms/step - loss: 0.7572 - accuracy: 0.6862 - val_loss: 1.1462 - val_accuracy: 0.5785\n","Epoch 18/25\n","573/573 [==============================] - 141s 247ms/step - loss: 0.7393 - accuracy: 0.7037 - val_loss: 1.1665 - val_accuracy: 0.5707\n","Epoch 19/25\n","573/573 [==============================] - 140s 245ms/step - loss: 0.7207 - accuracy: 0.7124 - val_loss: 1.1761 - val_accuracy: 0.5820\n","Epoch 20/25\n","573/573 [==============================] - 134s 234ms/step - loss: 0.7011 - accuracy: 0.7166 - val_loss: 1.2367 - val_accuracy: 0.5742\n","Epoch 21/25\n","573/573 [==============================] - 135s 236ms/step - loss: 0.6900 - accuracy: 0.7259 - val_loss: 1.2258 - val_accuracy: 0.5802\n","Epoch 22/25\n","573/573 [==============================] - 134s 234ms/step - loss: 0.6753 - accuracy: 0.7329 - val_loss: 1.2513 - val_accuracy: 0.5703\n","Epoch 23/25\n","573/573 [==============================] - 133s 232ms/step - loss: 0.6639 - accuracy: 0.7359 - val_loss: 1.2962 - val_accuracy: 0.5902\n","Epoch 24/25\n","573/573 [==============================] - 133s 232ms/step - loss: 0.6515 - accuracy: 0.7381 - val_loss: 1.3103 - val_accuracy: 0.6023\n","Epoch 25/25\n","573/573 [==============================] - 133s 232ms/step - loss: 0.6478 - accuracy: 0.7431 - val_loss: 1.3267 - val_accuracy: 0.6231\n","Train Accuracy: 0.8215  Test Accuracy: 0.7413\n"]}]}]}